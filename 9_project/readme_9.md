Task 1.1
Давай загрузим датасет CIFAR-10. Допиши функцию load_dataloaders с помощью torchvision.datasets.CIFAR10 и torch.utils.data.DataLoader, чтобы функция возвращала DataLoaderы для train и test частей датасета.
C помощью функции len количество батчей в train_loader и test_loader.

Для DataLoader параметры transform и batch_size оставь по умолчанию.

Task 1.2
Узнай, как из объекта DataLoader можно получить изображения и метки.
Передай первые 4 изображения и метки из первого батча тестовой выборки в функцию imshow. С помощью нее можно визуализировать датасет.
Должна получиться примерно такая визуализация: sample

Картинки и метки могут отличаться. Главное чтобы метки сходились с изображениями)

Task 1.3
Теперь попробуем написать небольшую сверточную нейронную сеть, которую мы будем обучать классифицировать изображения.

Напишем сеть, основанную на одном блоке архитектуры ResNet - Residual-Block. Схема этого блока приведена ниже:


Допиши класс ResidualNet:

Все сверточные слои должны иметь 32 выходных канала, а также не должны изменять ширину и высоту изображения.
Также в сверточных слоях padding = 1
Функции, которые тебе понадобятся: Conv2d, BatchNorm2d, ReLU.

Для базовой проверки, что сеть написана верно, этот код не должен выдавать ошибку
assert net(torch.zeros((10, 3, 32, 32))).shape == (10, 10)

Task 1.4
Перейдем к обучению сети. В этом поможет класс Trainer.
Для обучения, кроме самой модели, требуется определить оптимизатор и функцию ошибок:

В качестве оптимизатора выбери стохастический градиентный спуск
В качестве функции ошибок кросс-энтропия
Обучи сеть и с помощью функции plot_train_log, визуализируй процесс обучения модели.

Task 1.5
Одной стандартной техникой, применяющейся в глубинном обучении, а особенно часто в компьютерном зрении, являются аугментации данных.
Суть аугментаций состоит в том, что мы можем некоторым синтетическим образом видоизменять объекты обучающей выборки, тем самым расширяя ее, а также делая итоговую модель более устойчивой к таким изменениям. Наиболее удобным способом работы с аугментациями в PyTorch является их задание в списке transforms, который затем передается в Dataloader.
Изучи, какие способы аугментаций изображений можно использовать в PyTorch. Выбери несколько из них и визуализируй, как изменился датасет. sample sample

Обучи сеть с аугментацией данных и с помощью функции plot_train_log, визуализируй процесс обучения модели.

Natural Language Processing
В этой части проекта ты познакомишься с обработкой естественного языка и решишь задачу классификации токсичных комментариев. Работать мы будем с 160.000 комментариями, которые были помечены оценщиками как токсичное поведение. Различные платформы/сайты могут иметь различные стандарты для процесса отбора токсичных комментариев. Поэтому комментарии помечаются 6 категориями: toxic, severe_toxic, obscene, threat, insult, identity_hate.

Task 2.1
Загрузи датасет. Отрисуй Bar-plot с количеством комментариев для каждой категории токсичности и комментариев без токсичности. sample Выведи эти количества для каждой категории.

Task 2.2
Используя библиотеку nltk, обработай тексты комментариев:

Приведи текст к нижнему регистру и токенизируй
Оставь токены, являющимися английскими словами
Убери знаки препинания/цифр
Убери стоп-слова из библиотеки nltk
Выведи количество токенов для комментария с индексом 000103f0d9cfb60f

Task 2.3
Раздели выборку на тренировочную и тестовую с параметрами random_state=21, test_size=0.3, shuffle=True Преобразуй тексты комментариев с помощью TF-IDF с количеством признаков, равному 3000.
Выведи размерность тренировочной выборки после преобразования текста.

Task 2.4
Реши задачу Multi-Label классификации, используя RidgeClassifier. Посчитай значение ROC-AUC для тестовой выборки.

Task 2.5
Если посмотреть на тексты токсичных комментариев, то можно заметить, что они могут повторять одни и те же слова. Или там чаще встречается ! знаки.
Кроме 'прямых' текстовых признаков, можно использоваться и эту статистику по тексту. Например, долю уникальных слов в тексте комментария или количество пунктуации в тексте.

Придумай не меньше 4-х признаков, которые могут помочь в обучении модели. Добавь их к признакам TF-IDF и обучи модель. Получилось ли увеличить качество классификации?

Audio
В этой части проекта ты познакомишься с анализом аудио. Скачай датасет с аудио записями. Все они были записаны одним и тем же мужчиной, говорящим на иврите. В каждом файле человек произносит 8 слов; каждое слово на иврите означает либо "да", либо "нет", поэтому каждый файл представляет собой случайную последовательность из 8 "да" или "нет". Отдельной расшифровки не предусмотрено; последовательность закодирована в названии файла, например, 1 означает "да", а 0 - "нет" Давай попробуем реализовать классификатор слов - произносится "да"/"нет".

Task 3.1
Для начала познакомимся с этими записями.
Установи библиотеку librosa. Это популярная библиотека для работы с аудио. Визуализируй аудио сигнал файла 0_1_0_1_1_1_0_0.wav с помощью функции librosa.display.waveshow График должен быть такой же, как показано ниже (по значениям):

waveform

Для того, чтобы прослушать это аудио файл, можешь воспользоваться IPython.display.Audio.

Task 3.2
Для классификации обычно используют не просто аудио сигнал, а его частотно-временное представление. Для этого сигнал требуется преобразовать с помощью оконного преобразования Фурье. С помощью функции librosa.display.specshow выведи спектрограмму сигнала.
График должен быть такой же, как показано ниже (по значениям): sftp

Task 3.3
C помощью функции load_dataset загрузи датасет.
Раздели его на train и test c параметрами test_size=0.2, random_state=42.
Выведи количество файлов в train и test частях.

Task 3.4
Наши аудио записи содержат как речь человека, так и молчание. Для каждой записи нам нужно определить сегменты записи, где человек молчит, а где произносит слова.
Эта задача называется Voice Activity Detection (VAD). Придумай или найди метод, по которому можно распознавать участки с речью на аудио записи.

Например: Запись '0_0_0_1_0_1_1_0.wav' содержит 137592 отсчетов. Сегменты с речью для этой записи (Отмечены красным): [[23996, 32539], [35410, 44925], [49493, 57410], [60458, 68635], [73308, 81278], [84001, 91942], [97381, 104166], [109018, 115573]] sftp

Выведи несколько примеров работы твоего VAD-алгоритма, по аналогии с примером, для других аудио записей. Попробуй добиться наилучшего качества нахождения речи.

Task 3.5
После того как мы узнали сегменты аудио с речью, то можно перейти к самой задаче классификации.
Внимательно изучи функцию make_dataset. С помощью этой функции cгенерируй X, Y для train и test выборок. Затем попробуй обучить различные классификаторы. Например, SVM или LogisticRegression. Измерь точность (accuracy) классификации на тестовой выборке.
